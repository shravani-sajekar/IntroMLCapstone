# IntroMLCapstone

## Introduction
This is the capstone project for **Intro to Machine Learning**, focusing on predicting housing prices using both classical ML algorithms and literature-based machine learning methods.  
The project uses the Kaggle **House Prices: Advanced Regression Techniques** dataset.  
The goal is to implement classical ML models, reproduce methods from recent research papers, and compare their performance on the housing price prediction task.

---

## Repository Structure

This section includes every file and folder is described in detail.

```bash
IntroMLCapstone/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ X_processed.npz
â”‚ â”œâ”€â”€ X_test_processed.npz
â”‚ â”œâ”€â”€ data_description.txt
â”‚ â”œâ”€â”€ knn_val_predictions.npy
â”‚ â”œâ”€â”€ lr_val_predictions.npy
â”‚ â”œâ”€â”€ nn_metrics.json
â”‚ â”œâ”€â”€ nn_val_predictions.npy
â”‚ â”œâ”€â”€ paper1_xgb_metrics.json
â”‚ â”œâ”€â”€ paper1_xgb_test_predictions.npy
â”‚ â”œâ”€â”€ paper1_xgb_val_predictions.npy
â”‚ â”œâ”€â”€ paper2_rf_val_predictions.npy
â”‚ â”œâ”€â”€ paper2_xgb_val_predictions.npy
â”‚ â”œâ”€â”€ test.csv
â”‚ â”œâ”€â”€ train.csv
â”‚ â”œâ”€â”€ y.csv
â”‚ â””â”€â”€ y_val.npy
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ preprocessing.ipynb
â”‚       - Loads raw Kaggle dataset
â”‚       - Handles missing values, encodes categorical variables
â”‚       - Performs transformations, normalization, train/validation split
â”‚       - Saves train/val arrays to the data/ folder
â”‚
â”œâ”€â”€ classic_models/
â”‚   â”œâ”€â”€ linear_regression.ipynb
â”‚   â”œâ”€â”€ knn_regressor.ipynb
â”‚   â””â”€â”€ neural_network_regressor.ipynb
â”‚       - Implements baseline classic ML models
â”‚       - Saves predictions into data/ for unified comparison
â”‚
â”œâ”€â”€ paper_models/
â”‚   â”œâ”€â”€ paper1_xgboost.ipynb
â”‚   â””â”€â”€ paper2_bayesopt_rf_and_xgb.ipynb
â”‚       - Reproduces methodology from 2024 research papers
â”‚       - Includes Bayesian Optimization, XGBoost tuning, feature importance
â”‚
â”œâ”€â”€ results/
â”‚ â”œâ”€â”€ all_models_metrics.ipynb
â”‚ â”œâ”€â”€ best_model_actual_vs_pred.png
â”‚ â”œâ”€â”€ best_model_residuals.png
â”‚ â”œâ”€â”€ mae_comparison.png
â”‚ â”œâ”€â”€ metrics_table.png
â”‚ â”œâ”€â”€ model_comparison_metrics.csv
â”‚ â”œâ”€â”€ r2_comparison.png
â”‚ â””â”€â”€ rmse_comparison.png
â”‚       - Stores consolidated metrics, plots, and visual results
â”‚
â”œâ”€â”€ requirements.txt
â”‚   - All libraries needed to run the project
â”‚
â””â”€â”€ README.md
    - Project overview and file descriptions
```

**Folder/File Descriptions:**

- `data/` â€“ Preprocessed datasets, intermediate outputs, saved predictions, and raw CSV files.  
- `preprocessing/` â€“ Notebook for cleaning, encoding, scaling, and preparing features.  
- `classic_models/` â€“ Classic ML models (Linear Regression, KNN, Neural Network).  
- `paper_models/` â€“ Literature-based models (Paper 1 XGBoost, Paper 2 Bayesian-Optimized models).  
- `results/` â€“ Evaluation results, metrics tables, and visualizations for all models.  
- `README.md` â€“ Project documentation (this file).  
- `requirements.txt` â€“ Python package dependencies.

## Project Objective

To compare traditional machine learning algorithms with state-of-the-art literature-based models for the task of housing price prediction, and determine whether advanced models significantly outperform classical techniques.

This includes:

1. Full data preprocessing

2. Implementing 3 classical ML models

3. Reproducing methods from 2 recent research papers

4. Evaluating all models on the same validation split

5. Comparing performance using RMSE, MAE, MSE, RÂ²

6. Visualizing predictions and residuals


## Models Implemented

### Classic ML Models
1. **Linear Regression** â€“ Baseline regression model.  
2. **KNN Regressor** â€“ K-nearest neighbors regression.  
3. **Neural Network Regressor** â€“ MLPRegressor from scikit-learn.

### Literature-Based Models
1. **Paper 1: XGBoost** â€“ From â€œAn Optimal House Price Prediction Algorithm: XGBoostâ€ (2024, arXiv)  
   - Includes preprocessing, hyperparameter tuning, and feature importance.  
2. **Paper 2: Bayesian-Optimized Random Forest** â€“ From â€œHouse Price Prediction with Optimistic Machine Learning Methods Using Bayesian Optimizationâ€ (2024, SCITEPRESS)  
   - Implements Bayesian Optimization for hyperparameter tuning.  

All models are trained and evaluated using the Kaggle House Prices dataset. Performance metrics include **Mean Squared Error (MSE)** and **Mean Absolute Error (MAE)**. Visualizations such as residual histograms and predicted vs. actual plots are included in the `results/` folder.

---

## How to Run

1. Install dependencies:
```bash
pip install -r requirements.txt
```
2. Run preprocessing:
```bash
python preprocessing/preprocessing.ipynb
```

3. Run classic ML models:
```bash
python classic_models/linear_regression.ipynb
python classic_models/knn_regressor.ipynb
python classic_models/neural_network_regressor.ipynb
```

4. Run literature-based models:
```bash
python paper_models/paper1_xgboost.ipynb
python paper_models/paper2_bayesopt_rf.ipynb
```

5. View Results
```bash
results/all_models_metrics.ipynb
results/final_summary_dashboard.ipynb
```
   

## ðŸ“š References

> **Paper 1: XGBoost**
   - Title: *â€œAn Optimal House Price Prediction Algorithm: XGBoostâ€*  
   - Year: 2024  
   - Source: arXiv  
   - Link: [https://arxiv.org/abs/2402.04082](https://arxiv.org/abs/2402.04082)

> **Paper 2: Bayesian-Optimized Models**
   - Title: *â€œHouse Price Prediction with Optimistic Machine Learning Methods Using Bayesian Optimizationâ€*  
   - Year: 2024  
   - Source: SCITEPRESS  
   - Link: [https://www.scitepress.org/Papers/2024/128254/128254.pdf](https://www.scitepress.org/Papers/2024/128254/128254.pdf)

> **Dataset**
   - Kaggle: *House Prices â€“ Advanced Regression Techniques*  
   - Link: [https://www.kaggle.com/c/house-prices-advanced-regression-techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)







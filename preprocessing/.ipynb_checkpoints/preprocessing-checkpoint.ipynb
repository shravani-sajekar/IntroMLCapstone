{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eca9474",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline for Housing Price Prediction\n",
    "\n",
    "This notebook performs complete preprocessing of the training and test datasets, including:\n",
    "\n",
    "- Loading raw data  \n",
    "- Separating numerical and categorical features  \n",
    "- Handling missing values  \n",
    "- Standardizing numerical variables  \n",
    "- One-hot encoding categorical variables  \n",
    "- Saving processed data for modeling  \n",
    "\n",
    "The final outputs are:\n",
    "- `X_processed.npz` – preprocessed feature matrix (training)\n",
    "- `X_test_processed.npz` – preprocessed feature matrix (test)\n",
    "- `y.csv` – target variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17003c",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099c5f6f",
   "metadata": {},
   "source": [
    "We first import all required Python libraries. Pandas and NumPy handle data manipulation, scikit-learn provides preprocessing tools, and SciPy lets us save sparse matrices efficiently. Loading these libraries up front ensures the notebook environment is prepared for all preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46046aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f95dfe",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f74325b",
   "metadata": {},
   "source": [
    "We load the training and test datasets from the `data/` directory. Inspecting the shape and first few rows helps confirm that the files are correctly formatted and that the expected number of features is present. This step also allows us to visually assess missing values and data types before preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b5a78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1460, 81)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training and test datasets\n",
    "\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "print(\"Training data shape:\", train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825040b2",
   "metadata": {},
   "source": [
    "### Identify Numeric & Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b510e",
   "metadata": {},
   "source": [
    "Machine learning models treat numeric and categorical variables differently. Numeric features often require scaling to normalize ranges, while categorical features require encoding into numerical format. Automatically detecting feature types ensures our preprocessing pipeline adapts correctly to the dataset structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "468692fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: 37\n",
      "Categorical features: 43\n"
     ]
    }
   ],
   "source": [
    "# Identify numeric and categorical features\n",
    "\n",
    "numeric_features = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target variable from numeric list\n",
    "\n",
    "numeric_features.remove(\"SalePrice\")  #target column\n",
    "\n",
    "print(\"Numeric features:\", len(numeric_features))\n",
    "print(\"Categorical features:\", len(categorical_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f7f2f",
   "metadata": {},
   "source": [
    "### Handle Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59437850",
   "metadata": {},
   "source": [
    "Missing values can disrupt model training or introduce bias.  \n",
    "- Numeric features are imputed using the median because it is robust to outliers.  \n",
    "- Categorical features are imputed using the mode to preserve the most common category.\n",
    "\n",
    "Consistent imputation across training and test sets ensures the model receives uniform feature distributions during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfba0934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value handling completed.\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in numeric features using median\n",
    "\n",
    "train_df[numeric_features] = train_df[numeric_features].fillna(train_df[numeric_features].median())\n",
    "test_df[numeric_features] = test_df[numeric_features].fillna(train_df[numeric_features].median())\n",
    "\n",
    "# Fill missing values in categorical features using mode\n",
    "\n",
    "train_df[categorical_features] = train_df[categorical_features].fillna(train_df[categorical_features].mode().iloc[0])\n",
    "test_df[categorical_features] = test_df[categorical_features].fillna(train_df[categorical_features].mode().iloc[0])\n",
    "\n",
    "print(\"Missing value handling completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97b2b5e",
   "metadata": {},
   "source": [
    "### Split Features and Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b95d01",
   "metadata": {},
   "source": [
    "Machine learning models learn to predict a specific target variable—in this case, `SalePrice`. We separate the dataset into:\n",
    "- `X`: input features  \n",
    "- `y`: target output  \n",
    "\n",
    "This separation allows preprocessing to be applied consistently to inputs while preserving the target for supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76eb3149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (1460, 80)\n",
      "Target vector shape: (1460,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "\n",
    "X = train_df.drop(\"SalePrice\", axis=1)\n",
    "y = train_df[\"SalePrice\"]\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Target vector shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e23db",
   "metadata": {},
   "source": [
    "### Build Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950446b2",
   "metadata": {},
   "source": [
    "A `ColumnTransformer` is used to apply different transformations to numeric and categorical columns:\n",
    "- **StandardScaler** normalizes numeric values, improving gradient-based model performance.\n",
    "- **OneHotEncoder** converts categorical variables into binary indicator columns, enabling models to interpret non-numeric information.\n",
    "\n",
    "Using a pipeline ensures that all preprocessing steps are applied consistently and can later be reused during model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed55a4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature preprocessing completed.\n",
      "Processed training feature matrix shape: (1460, 289)\n",
      "Processed test feature matrix shape: (1459, 289)\n"
     ]
    }
   ],
   "source": [
    "# Create a preprocessing pipeline with scaling and encoding\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit-transform training data and transform test data\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "X_test_processed = preprocessor.transform(test_df)\n",
    "\n",
    "print(\"Feature preprocessing completed.\")\n",
    "print(\"Processed training feature matrix shape:\", X_processed.shape)\n",
    "print(\"Processed test feature matrix shape:\", X_test_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb90414",
   "metadata": {},
   "source": [
    "### Save Processed Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b01e86",
   "metadata": {},
   "source": [
    "The processed feature matrices are saved in sparse `.npz` format to reduce storage space, especially since one-hot encoding can dramatically increase dimensionality. The target vector `y` is saved as a CSV file. These processed files will be directly loaded by the model training notebooks, ensuring complete separation between preprocessing and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d62d0e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed & files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save transformed matrices as compressed sparse files\n",
    "\n",
    "sparse.save_npz(\"../data/X_processed.npz\", X_processed)\n",
    "sparse.save_npz(\"../data/X_test_processed.npz\", X_test_processed)\n",
    "\n",
    "# Save target variable\n",
    "\n",
    "y.to_csv(\"../data/y.csv\", index=False)\n",
    "\n",
    "print(\"Preprocessing completed & files saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
